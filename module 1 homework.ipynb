{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2173fba-3917-4bc0-93e5-732c2449b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Homework ########\n",
    "\n",
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2feaa9-2b96-4699-9bf4-ffdf613f6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"How do I execute a command in a running docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3068a8c-6b6c-40fe-8b1f-d2538424986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a412c5b-6e83-4537-9839-0bd8192819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es_client.search(index=index_name,q=query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8bb13-0090-496e-a881-e3d0f9230f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1a205-fe28-428a-83e8-1affb3228c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e11c83-0e57-4a2e-87fa-4bec1e2b67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac9326-e4cb-4e10-99d5-c758ca52dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template is for giving a role, good practice for better response, for more advacne model we need it\n",
    "\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    QUESTION: {question}\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "        prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(query,results)\n",
    "\n",
    "#client = OpenAI(api_key=os.getenv('OPEN_API_KEY'))\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "print(len(response.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
